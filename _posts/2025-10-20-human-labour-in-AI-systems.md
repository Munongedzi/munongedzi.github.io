---
layout: post
title: "Human Labour in AI Systems"
date: 2025-10-20
excerpt: AI is reorganizing work through task decomposition, algorithmic management, and surveillance. This essay synthesizes evidence on job change, distributional impacts, and governance reforms that center dignity, due process, and meaningful work.
---

## Human Labour in AI Systems

**Munongedzi Mabhoko**  
Email: [mabhokm@clarkson.edu](mailto:mabhokm@clarkson.edu)

## Introduction

Artificial intelligence (AI) in the workplace must be understood not only in terms of model development and data annotation but as a broader reconfiguration of everyday labor. From hospitals to warehouses, call centers to public agencies, AI alters how tasks are allocated, monitored, and valued. The central question is not simply “which jobs will AI replace?” but **“how does AI reorganize power and control in firms, and with what consequences for worker dignity and social welfare?”**

This article advances three contributions:

1. It synthesizes recent evidence on the ways AI changes tasks, skills, and management practices.  
2. It evaluates distributional impacts across social groups, geographies, and firm sizes.  
3. It outlines institutional reforms and design patterns to better align AI with equity, safety, and meaningful work.

## How Jobs Are Changing

AI’s impact on jobs cannot be reduced to substitution. Research shows that automation often eliminates tasks, not entire occupations (Acemoglu & Restrepo, 2020). Whether this produces upskilling or deskilling depends on design choices and on the values encoded into systems.

AI systems are not simply reshaping which jobs exist but redefining how work itself is organized, monitored, and valued. The relentless pursuit of “precision labor” in AI training exposes workers to hidden, excessive, and often unpaid tasks designed to meet arbitrary accuracy standards that privilege machine metrics over human judgment. This dynamic extends beyond annotation centers into the broader workplace, where algorithmic management and surveillance increasingly dictate hiring, scheduling, evaluation, and even termination.

Workers face a double bind: subordinated to machines as arbiters of “truth” while competing in gamified environments that erode dignity and autonomy. The result is a growing fear that humans are being transformed from decision-makers into supervisors of machine outputs, forced to think like AI to survive.

Addressing these harms requires moving beyond technical debates about accuracy and acknowledging the social construction of performance metrics, foregrounding worker agency, and developing governance frameworks that ensure AI augments rather than disciplines human labor.

### Evidence across sectors

- **Upskilling vs deskilling:** In healthcare, clinical decision support can augment physicians by detecting early warning signs of sepsis (Brynjolfsson, 2023). Yet Levy warns that safety logics can rationalize intrusive oversight. If AI turns doctors into box-checkers rather than decision makers, skill erosion results (Levy, 2022).  
- **Retail and logistics:** Amazon warehouses deploy AI-driven robotics to accelerate sorting, but human workers report monotonous, injury-prone stowing tasks left for them. The ideology of efficiency hides real costs: injuries, fatigue, and turnover absorbed by workers (Levy, 2022).  
- **Call centers:** Rosenblat’s analysis of ride-hailing offers a parallel. Just as drivers are nudged by algorithmic prompts, call center agents are nudged into scripted behaviors, narrowing autonomy and creativity (Rosenblat, 2018).  
- **Public services:** In welfare systems, automated eligibility assessments reduce staff discretion and risk unfair denials (Eubanks, 2018). Here, algorithmic decisions are justified as neutral, but Levy shows how “objectivity” often masks organizational attempts to discipline workers and clients alike.

Not all tasks are equally suited for automation. Scholars caution against extending AI into domains that hinge on empathy, contextual judgment, and moral accountability. Decisions such as medical triage, criminal sentencing, or eligibility assessments in social services are not merely technical problems but deeply human encounters where lives, dignity, and justice are at stake.

The ideology that “data knows best” risks obscuring the limits of statistical models and the harms that arise when they displace human care. Human oversight is not redundancy but a safeguard, ensuring decision-making remains accountable to ethical reasoning, lived experience, and complex individual needs.

## Algorithmic Management and Surveillance

Algorithmic management refers to delegating supervisory functions—scheduling, evaluation, and pay determination—to digital systems. Some describe this as a form of “digital Taylorism” that extends scientific management into data-driven micromonitoring, fragmenting and controlling labor in ways that echo early 20th-century factory practices.

Rosenblat argues algorithmic management is not neutral. It is an ideology of control wrapped in the language of flexibility and independence. Uber drivers are called entrepreneurs, yet pay and working hours are dictated by opaque algorithms. What looks like autonomy becomes dependence on invisible rules (Rosenblat, 2018).

Levy similarly shows how trucking surveillance reframes drivers as risks to be managed. Monitoring is justified in the name of safety, but the result is increased managerial oversight and the transfer of liability to workers (Levy, 2022).

### Key risks

- **Opacity** limits due process when workers cannot challenge automated evaluations (Rosenblat, 2018)  
- **Embedded bias** reproduces discrimination patterns  
- **Constant monitoring** chills autonomy and undermines collective action  

Advocates counter that algorithmic oversight can promote fairness through standardized criteria and enhance safety by flagging hazards. For example, AI-based fatigue monitoring in mining has been credited with reducing accidents (OECD, 2023). Yet, as Levy notes, safety rationales often conceal a deeper redistribution of responsibility: workers remain perpetually observable, firms capture productivity gains, and psychological strain intensifies.

## Distributional Impacts and Inequality

The distributional impacts of AI adoption show technological change is not neutral but stratified.

At the level of skills, AI accentuates polarization: highly educated professionals capture productivity gains through complementarity, while lower-skill workers face intensified monitoring and routinization. Across firms, adoption is uneven: large corporations can absorb costs of advanced systems while smaller enterprises fall behind, widening gaps in productivity and competitiveness.

Inequality is compounded by social hierarchies. Gendered and racialized labor markets place women, minorities, and migrants disproportionately in sectors most subject to algorithmic surveillance and control. Disability introduces a double edge: AI can reduce barriers but can also entrench exclusion when design flaws amplify bias.

Globally, these asymmetries extend to the Global South, where digital labor platforms position annotation and microwork as development opportunities even as they entrench vulnerability under opaque algorithmic control. In Kenyan microwork platforms, annotators earn low wages under strict algorithmic management, highlighting how AI globalizes precarious digital labor (Graham, 2020).

AI reorganizes inequality rather than dissolving it, redistributing advantage toward those with structural power while deepening precarity at the margins.

## Governance and Worker Power

The governance of algorithmic management demands a rebalancing of power between firms and workers. Current regimes of opacity—where rules for evaluation and pay are hidden—sustain asymmetry and undermine dignity.

Reversing this requires institutionalized channels for worker voice and consultation in AI design and deployment. Collective bargaining must evolve to include digital clauses that set boundaries on surveillance and embed rights to algorithmic review.

Just as physical safety equipment is subject to standards and inspection, algorithmic systems that shape livelihoods should be auditable, contestable, and accountable. Due process is central: workers need avenues of redress when automated systems determine pay, promotion, or termination.

Governments play a role in establishing baselines through impact assessments, transparency requirements, and enforceable limits on intrusive monitoring. Policies guaranteeing portability of skills across platforms and employers safeguard against technological lock-in. International norms on digital management can extend protections across borders.

## Solutions and Design Patterns

Levy and Rosenblat argue that the ideology of efficiency must be challenged with design logics of dignity and fairness.

- **Augmentation-first workflows:** Systems should enhance human judgment, not replace it  
- **Documentation:** System cards and labor impact statements should accompany deployment, outlining effects on autonomy, skill, and equity  
- **Metrics beyond productivity:** Evaluation should include worker discretion, psychological safety, opportunities for learning, and fairness of outcomes  

## Risks and Mitigations

| Risk | Mitigation | Evidence |
|---|---|---|
| Deskilling of healthcare workers | Training integrated with AI support; mandatory override rights | (Brynjolfsson, 2023) |
| Algorithmic bias in evaluations | Independent audits; explainable models | (AI Now, 2021) |
| Warehouse injuries from pacing | Ergonomic design; non-punitive monitoring | (Levy, 2022) |
| Precarious scheduling | Minimum hour guarantees; worker input into rosters | (OECD, 2023) |
| Algorithmic opacity in gig work | Worker access to data logs; appeals processes | (Rosenblat, 2018) |

## Open Questions and Research Agenda

Significant gaps remain:

- Longitudinal studies on skill trajectories under AI-enabled management  
- Comparative research across Global South contexts  
- Pilot programs testing labor impact statements  
- Measurement frameworks for dignity and discretion in work  
- Ideological analysis of how firms justify AI adoption, building on Rosenblat’s flexibility myths and Levy’s safety logics  

## Conclusion

AI is not destiny. It reshapes everyday work through choices about what tasks to automate, how to govern algorithmic systems, and whose voices to include. Benefits in safety and productivity are real, but so are harms of surveillance, inequality, and deskilling.

Rosenblat reminds us that algorithmic management is not just technology but ideology: a story told to workers about freedom while constraining their choices. Levy reminds us that surveillance justified as safety is still surveillance.

The challenge is to align AI with worker dignity through stronger institutions, participatory governance, and augmentation-first design. The path forward is one of trade-offs: balancing efficiency with fairness, innovation with accountability, and productivity with humanity.

---

## References

- Acemoglu, D., & Restrepo, P. (2020). Robots and Jobs: Evidence from US Labor Markets. *Journal of Political Economy, 128*(6), 2188–2244.  
- AI Now Institute. (2021). *Algorithmic Impact Assessments: A Practical Framework for Public Agency Accountability.* AI Now Report.  
- Brynjolfsson, E., Li, D., & Raymond, L. (2023). Augmented Intelligence in Healthcare: Productivity and Learning. *NBER Working Paper.*  
- Crawford, K. (2021). *Atlas of AI: Power, Politics, and the Planetary Costs of Artificial Intelligence.* Yale University Press.  
- Eubanks, V. (2018). *Automating Inequality: How High-Tech Tools Profile, Police, and Punish the Poor.* St. Martin’s Press.  
- Graham, M., Hjorth, I., & Lehdonvirta, V. (2020). Digital Labour and Development: Impacts of Global Microwork Platforms. *Development and Change, 51*(3), 683–710.  
- International Labour Organization (ILO). (2022). *The Role of Digital Labour Platforms in Transforming Work.* Geneva.  
- Levy, K. (2022). *Data Driven: Truckers, Technology, and the New Workplace Surveillance.* Princeton University Press.  
- Mateescu, A., & Nguyen, A. (2019). *Algorithmic Management in the Workplace.* Data & Society Research Institute.  
- OECD. (2023). *AI in Work, Innovation, Productivity and Skills.* OECD Publishing.  
- Rosenblat, A. (2018). *Uberland: How Algorithms Are Rewriting the Rules of Work.* University of California Press.  
