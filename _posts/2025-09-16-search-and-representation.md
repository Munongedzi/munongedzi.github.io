---
layout: post
title: "Search and Representation: Situating Algorithms of Oppression"
date: 2025-09-16
excerpt: This essay reads search as soft governance, arguing that ranking systems produce public meaning through commercial incentives, classification power, and predictable representational harms—especially for identity-linked queries.
---

## Search and Representation  
*(Situating* Algorithms of Oppression *by Safiya Umoja Noble)*

**Munongedzi Mabhoko, Clarkson University**  
Email: [mabhokm@clarkson.edu](mailto:mabhokm@clarkson.edu)

## Search as Soft Governance

Treat search not as a helpful index but as a form of **soft governance**. A results page functions like a miniature policy decision that defines who is visible, assigns authority, determines what counts as knowledge, and decides which narratives are granted credibility—or which stories about people become thinkable.

The popular story that search is a neutral conduit survives because the interface is clean and the page is free to use. The book’s most important move is to insist we look at the economics and curation underneath the surface, where “relevance” is produced inside ad markets and partnerships, and where the first screen becomes an auctioned gateway to meaning. Neutrality becomes an appearance sustained by commercial choices, and users are trained to accept the page as if it were assembled by a kindly librarian rather than a revenue machine.

The most useful way to read *Algorithms of Oppression* is not as a catalogue of bias incidents but as a theory of how search governs representation. Once neutrality is set aside, the key question becomes: not only whether links are relevant, but **for whom relevance has been engineered**.

## Digital Redlining and Classification Power

Once the neutrality story collapses, the analysis turns to what Noble calls **digital redlining**. The term echoes a familiar urban practice where literal lines on maps excluded communities from credit and investment. The instruments differ, but the effect is similar: authority and opportunity flow to some neighborhoods of knowledge, while other neighborhoods are made difficult to find or are represented primarily through degrading tropes.

The shift from paper maps to algorithmic lists hides the line-drawing from public view and places it behind proprietary ranking. The lines are still there. They are inscribed through data licensing, ad auctions, and optimization signals that convert historical prejudice into “user interest.”

To reinterpret this opening argument, begin with **classification**. Classification is never merely technical. It is cultural power that authorizes an order of the world. When a query about professional hair surfaces images that associate “unprofessional” with Black women’s natural styles, the system is not simply echoing the web. It is rehearsing a long media history that marked Black appearance as deviant—and doing so at the very moment people treat search output as a shared reference point.

Pornographic returns on simple identity terms work the same way. They recast broad groups as objects of sexual curiosity and make that portrayal feel like public consensus because it appears at the top of the page. The page is profitable. It is also pedagogical. It teaches users who belongs where in the social imagination.

## Ranking as Narrative Power

These examples matter less as “gotchas” than as evidence that ranking has a **representational logic**. It rewards what sells attention and normalizes what advertisers find comfortable. The harms at stake are not only factual errors. They are patterned portrayals that stereotype people or erase them as experts.

The deeper claim is that classification power becomes **narrative power**. Search does not just retrieve pages. It assembles mini narratives through ordering, snippets, and repetition of similar sources, so that certain explanations appear corroborated by quantity and position.

The commercial motive seeks engagement and conversion. The government motive seeks prediction and control. Both require large, labeled populations. Both are served by infrastructures that sort people by alleged risk, desirability, or credibility. In this alignment, search is not peripheral. It is a social control surface through which populations are represented to themselves and to one another. The harms described in the book are therefore not only incidents of bad data. They are predictable outcomes of a political economy that monetizes attention and privileges frictionless curation over civic obligation.

## A Neighboring Domain: Dating Platforms and Visibility

One way to test this interpretation is to step outside classical “search” and examine a neighboring domain that also ranks people. Studies of dating platforms for Black women reveal systems that actively shape who is visible and who is ignored. Engagement-based sorting decides which faces appear and in what order, with opacity that prevents users from understanding or contesting the rules. Even when users pay to boost visibility, whiteness remains the normative baseline.

These findings are not about romance alone. They expose how ranking regimes convert social bias into an interface that looks like personal choice. The architecture of desirability on these apps resembles the architecture of authority on results pages.

The point is not that dating and search are the same. It is that they share a grammar: both are gatekeepers that convert collective behavior and business goals into the lived experience of who is available and credible. Both harvest clicks to decide what counts as desirable or authoritative. Both teach users to read social order as though it were the product of their own choices.

## Beyond Race and Gender: Language and Religion

A structural approach is incomplete if it stops at race and gender. One of the studies referenced argues that language and religion shape digital power yet remain underexamined in mainstream intersectional work. Since early internet protocols privileged English and Roman characters, participation and design authority have been unevenly distributed. Even today, customer service workers are coached to present whiteness in voice and name. Large language models can amplify these imbalances by baking English defaults into the production of meaning.

Religion, too, organizes belonging and exclusion and has historically underwritten categories of the human that travel into data work. Attending to these layers provides a more complete map of how search can misrecognize people long before they arrive at a query.

## Sexualization and Securitization as Infrastructure Effects

Two representational patterns thrive in commercial ranking:

1. **Sexualization:** identity terms and innocuous searches for girls and women routed to pornography  
2. **Securitization:** crime-adjacent queries that frame racialized threat as obvious fact  

Both patterns emerge from the same infrastructure. They monetize desire and fear while outsourcing responsibility to “what users clicked.” This perspective shifts attention from individual intention to institutional logic. It foregrounds interlocking hierarchies of race, gender, class, ability, and sexuality, asking how technology sediments those hierarchies into everyday sense-making.

## What the Questions Should Become

If this structural reading holds, then the key questions change. Instead of asking whether a particular query is “biased,” probe the representational distribution a system generates across time for identity-linked terms:

- Which portrayals recur?  
- Which portrayals are missing?  
- Which are monetized?

Interrogating “relevance” becomes unstable when relevance is inferred from past clicks that were shaped by earlier ranking choices. Instead, consider the **dignity floor** a results page should guarantee when the query is about a group of people.

If ad engines can implement brand safety filters in milliseconds, the infrastructure already supports rapid demotion of demeaning material. The barrier is not technical capacity. It is the absence of a public mandate that places human dignity above auction outcomes. Search operators already prioritize profit; they could prioritize public interest when compelled—or when they choose to.

## Policy and Public Literacy

Search shapes ordinary sense-making long before anyone reaches policing or security. A system that claims to know what you want to see next becomes a device for governing who appears as credible, desirable, or dangerous. A search result is not a mirror. It is an instrument for **predictive representation**.

Policy should therefore recognize ranking systems as public-facing infrastructures with public effects. Several implications follow:

- Transparency around auction dynamics for identity-linked queries would enable independent audits of how money intersects with representation  
- Restrictions on monetization for dignity-sensitive terms would prevent the direct sale of demeaning portrayals as first-page authority  
- Search and recommendation should be treated as knowledge infrastructures carrying obligations closer to broadcasting and libraries, not mere conduits  

This framing also belongs in classrooms. Traditional media literacy trains people to spot fake news and triangulate sources. That remains useful, but the literacy demanded now is **infrastructure literacy**. Students should learn to read a results page as an editorial art
